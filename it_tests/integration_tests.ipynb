{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `hops-util-py` Integration Tests\n",
    "\n",
    "This notebook can be converted to a python file and submitted as a spark job for integration tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6</td><td>application_1551827646377_0017</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8088/proxy/application_1551827646377_0017/\">Link</a></td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8042/node/containerlogs/container_e01_1551827646377_0017_01_000001/demo_featurestore_admin000__meb10000\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from hops import experiment, hdfs, tensorboard, devices, kafka, featurestore, tls, util\n",
    "import stat\n",
    "import os\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, IntegerType, FloatType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from pyspark.sql import DataFrame\n",
    "from petastorm.unischema import dict_to_spark_row, Unischema, UnischemaField\n",
    "from petastorm.codecs import ScalarCodec, CompressedImageCodec, NdarrayCodec\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session With Hive Enabled (In case Running as a Job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Custom Experiments\n",
    "\n",
    "- `experiment.begin()`\n",
    "- `experiment.end()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.begin(name='some custom thing 1', local_logdir=False)\n",
    "assert tensorboard.logdir() != None\n",
    "pi = 1+3+0.14\n",
    "experiment.end(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.begin(name='some custom thing 2', local_logdir=True, description='i am making custom exp on hops')\n",
    "assert tensorboard.logdir() != None\n",
    "pi = 1337\n",
    "experiment.end(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test `experiment.launch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper():\n",
    "    assert tensorboard.logdir() != None\n",
    "    assert devices.get_num_gpus() >= 0\n",
    "    assert hdfs.project_path() == hdfs.project_path(hdfs.project_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0004/launcher/run.1'"
     ]
    }
   ],
   "source": [
    "experiment.launch(wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0004/launcher/run.2'"
     ]
    }
   ],
   "source": [
    "experiment.launch(wrapper, name='simple exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0004/launcher/run.3'"
     ]
    }
   ],
   "source": [
    "experiment.launch(wrapper, local_logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0004/launcher/run.4'"
     ]
    }
   ],
   "source": [
    "experiment.launch(wrapper, description='very interesting description', local_logdir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_wrapper(a, b):\n",
    "    assert tensorboard.logdir() != None\n",
    "    assert devices.get_num_gpus() >= 0\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/launcher/run.1'"
     ]
    }
   ],
   "source": [
    "experiment.launch(parameter_wrapper, {'a': [1,3], 'b': [-1,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/launcher/run.2'"
     ]
    }
   ],
   "source": [
    "experiment.launch(parameter_wrapper, {'a': [1,3], 'b': [-1,1]},  name='simple exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/launcher/run.3'"
     ]
    }
   ],
   "source": [
    "experiment.launch(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, local_logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/launcher/run.4'"
     ]
    }
   ],
   "source": [
    "experiment.launch(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, description='very interesting description', local_logdir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Parallel Experiments `experiment.grid_search`, `experiment.random_search`, `experiment.differential_evolution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Grid Search results ------ direction(max) \n",
      "BEST combination a=3.b=1 -- metric 4.0\n",
      "WORST combination a=1.b=-1 -- metric 0.0\n",
      "AVERAGE metric -- 2.0\n",
      "Total job time 13 seconds\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/grid_search/run.1'"
     ]
    }
   ],
   "source": [
    "experiment.grid_search(parameter_wrapper, {'a': [1,3], 'b': [-1,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Grid Search results ------ direction(max) \n",
      "BEST combination a=3.b=1 -- metric 4.0\n",
      "WORST combination a=1.b=-1 -- metric 0.0\n",
      "AVERAGE metric -- 2.0\n",
      "Total job time 13 seconds\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/grid_search/run.2'"
     ]
    }
   ],
   "source": [
    "experiment.grid_search(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, direction='max', name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Grid Search results ------ direction(max) \n",
      "BEST combination a=3.b=1 -- metric 4.0\n",
      "WORST combination a=1.b=-1 -- metric 0.0\n",
      "AVERAGE metric -- 2.0\n",
      "Total job time 13 seconds\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/grid_search/run.3'"
     ]
    }
   ],
   "source": [
    "experiment.grid_search(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, direction='max', name='test', local_logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Random Search results ------ direction(max) \n",
      "BEST combination a=3.b=1 -- metric 4.0\n",
      "WORST combination a=1.b=-1 -- metric 0.0\n",
      "AVERAGE metric -- 1.8333333333333333\n",
      "Total job time 19 seconds\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/random_search/run.1'"
     ]
    }
   ],
   "source": [
    "experiment.random_search(parameter_wrapper, {'a': [1,3], 'b': [-1,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Random Search results ------ direction(max) \n",
      "BEST combination a=3.b=1 -- metric 4.0\n",
      "WORST combination a=2.b=-1 -- metric 1.0\n",
      "AVERAGE metric -- 2.2857142857142856\n",
      "Total job time 26 seconds\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/random_search/run.2'"
     ]
    }
   ],
   "source": [
    "experiment.random_search(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, direction='max', name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Random Search results ------ direction(min) \n",
      "BEST combination a=1.b=-1 -- metric 0.0\n",
      "WORST combination a=2.b=-1 -- metric 1.0\n",
      "AVERAGE metric -- 0.5\n",
      "Total job time 6 seconds\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0012/random_search/run.3'"
     ]
    }
   ],
   "source": [
    "experiment.random_search(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, direction='min', samples=3, name='test', local_logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args_dict:\n",
      "{'a': [1, 3], 'b': [-1, 1]}\n",
      "Generation 0 || average metric: 2.0, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 1 || average metric: 2.4, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 2 || average metric: 2.4, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 3 || average metric: 2.7, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 4 || average metric: 3.0, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 5 || average metric: 3.1, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 6 || average metric: 3.4, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 7 || average metric: 3.5, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 8 || average metric: 3.6, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 9 || average metric: 3.7, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Generation 10 || average metric: 3.9, best metric: 4.0, best parameter combination: ['a=3', 'b=1']\n",
      "\n",
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir1, result_dict1 = experiment.differential_evolution(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, local_logdir=True, direction='max')\n",
    "assert int(result_dict1['a']) == 3 and int(result_dict1['b']) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args_dict:\n",
      "{'a': [1, 3], 'b': [-1, 1]}\n",
      "Generation 0 || average metric: 2.2, best metric: 2.0, best parameter combination: ['a=3', 'b=-1']\n",
      "\n",
      "Generation 1 || average metric: 2.2, best metric: 2.0, best parameter combination: ['a=3', 'b=-1']\n",
      "\n",
      "Generation 2 || average metric: 1.6, best metric: 1.0, best parameter combination: ['a=2', 'b=-1']\n",
      "\n",
      "Generation 3 || average metric: 1.4, best metric: 1.0, best parameter combination: ['a=1', 'b=0']\n",
      "\n",
      "Generation 4 || average metric: 1.4, best metric: 1.0, best parameter combination: ['a=1', 'b=0']\n",
      "\n",
      "Generation 5 || average metric: 1.4, best metric: 1.0, best parameter combination: ['a=1', 'b=0']\n",
      "\n",
      "Generation 6 || average metric: 1.2, best metric: 0.0, best parameter combination: ['a=1', 'b=-1']\n",
      "\n",
      "Generation 7 || average metric: 0.8, best metric: 0.0, best parameter combination: ['a=1', 'b=-1']\n",
      "\n",
      "Generation 8 || average metric: 0.4, best metric: 0.0, best parameter combination: ['a=1', 'b=-1']\n",
      "\n",
      "Generation 9 || average metric: 0.2, best metric: 0.0, best parameter combination: ['a=1', 'b=-1']\n",
      "\n",
      "Generation 10 || average metric: 0.2, best metric: 0.0, best parameter combination: ['a=1', 'b=-1']\n",
      "\n",
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir2, result_dict2 = experiment.differential_evolution(parameter_wrapper, {'a': [1,3], 'b': [-1,1]}, generations=10, population=5, direction='min')\n",
    "assert int(result_dict2['a']) == 1 and int(result_dict2['b']) == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HopsFS Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test HopsFS operations\n",
    "\n",
    "- `hdfs.project_user()`\n",
    "- `hdfs.project_name()`\n",
    "- `hdfs.project_path()`\n",
    "- `hdfs.exists()`\n",
    "- `hdfs.load()`\n",
    "- `hdfs.copy_to_local()`\n",
    "- `hdfs.ls()`\n",
    "- `hdfs.lsl()`\n",
    "- `hdfs.glob()`\n",
    "- `hdfs.cp()`\n",
    "- `hdfs.rmr()`\n",
    "- `hdfs.rename()`\n",
    "- `hdfs.stat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_user = hdfs.project_user()\n",
    "project_name = hdfs.project_name()\n",
    "assert project_name in project_user\n",
    "project_path = hdfs.project_path()\n",
    "assert project_name in project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_README = hdfs.load(\"Logs/README.md\")\n",
    "assert len(logs_README) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.dump(\"test\", \"Logs/README_dump_test.md\")\n",
    "assert hdfs.exists(\"Logs/README_dump_test.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_README_dumped = hdfs.load(\"Logs/README_dump_test.md\")\n",
    "assert logs_README_dumped.decode(\"utf-8\") == \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w') as f:\n",
    "    f.write(\"test\")\n",
    "hdfs.copy_to_hdfs(\"test.txt\", \"Resources/test.txt\", overwrite=True)\n",
    "assert hdfs.exists(\"Resources/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.copy_to_local(\"Resources/test.txt\", \"\", overwrite=True)\n",
    "hdfs_copied_file = hdfs.load(\"Resources/test.txt\")\n",
    "with open('test.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == \"test\"\n",
    "assert local_copied_file == \"test\"\n",
    "assert hdfs.ls(\"Logs/\").__class__.__name__ == 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_md = hdfs.glob(\"Logs/*.md\")\n",
    "logs_path_names = hdfs.lsl(\"Logs/\")\n",
    "if hdfs.exists(\"Logs/test.txt\"):\n",
    "    hdfs.rmr(\"Logs/test.txt\")\n",
    "assert not hdfs.exists(\"Logs/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.cp(\"Resources/test.txt\", \"Logs/\")\n",
    "logs_files = hdfs.ls(\"Logs/\")\n",
    "assert \"test.txt\" in \",\".join(logs_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.mkdir(\"Logs/test_dir\")\n",
    "assert hdfs.exists(\"Logs/test_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_delete = hdfs.ls(\"Logs/\")\n",
    "hdfs.rmr(\"Logs/test_dir\")\n",
    "logs_files_after_delete = hdfs.ls(\"Logs/\")\n",
    "assert len(logs_files_prior_delete) > len(logs_files_after_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_move = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test.md\" in \",\".join(logs_files_prior_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.move(\"Logs/README_dump_test.md\", \"Logs/README_dump_test2.md\")\n",
    "logs_files_after_move = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test.md\" not in \",\".join(logs_files_after_move)\n",
    "assert \"README_dump_test2.md\" in \",\".join(logs_files_after_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_rename = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test2.md\" in \",\".join(logs_files_prior_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.rename(\"Logs/README_dump_test2.md\", \"Logs/README_dump_test.md\")\n",
    "logs_files_after_rename = hdfs.ls(\"Logs/\")\n",
    "assert \"Logs/README_dump_test2.md\" not in \",\".join(logs_files_after_rename)\n",
    "assert \"Logs/README_dump_test.md\" in \",\".join(logs_files_after_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "hdfs.chmod(\"Logs/README.md\", 775)\n",
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "assert 775 == file_stat.st_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.chmod(\"Logs/README.md\", 777)\n",
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "assert 777 == file_stat.st_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_owner = file_stat.st_uid\n",
    "assert hdfs.exists(\"Logs/\")\n",
    "assert not hdfs.exists(\"Not_Existing/neither_am_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Distributed Training MirroredStrategy (This may fail if not configured MirroredStrategy)\n",
    "\n",
    "- `experiment.mirrored()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirrored():\n",
    "    assert tensorboard.logdir() != None\n",
    "    assert devices.get_num_gpus() >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/mirrored/run.1'"
     ]
    }
   ],
   "source": [
    "experiment.mirrored(mirrored, local_logdir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/mirrored/run.2'"
     ]
    }
   ],
   "source": [
    "experiment.mirrored(mirrored, local_logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/mirrored/run.3'"
     ]
    }
   ],
   "source": [
    "experiment.mirrored(mirrored, name='mirrortime', description='such desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/mirrored/run.4'"
     ]
    }
   ],
   "source": [
    "experiment.mirrored(mirrored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Distributed Training CollectiveAllReduceStrategy (This may fail if not configured CollectiveAllReduceStrategy)\n",
    "\n",
    "- `experiment.collective_all_reduce()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collective():\n",
    "    assert 'TF_CONFIG' in os.environ\n",
    "    assert devices.get_num_gpus() >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/collective_all_reduce/run.1'"
     ]
    }
   ],
   "source": [
    "experiment.collective_all_reduce(collective, local_logdir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/collective_all_reduce/run.2'"
     ]
    }
   ],
   "source": [
    "experiment.collective_all_reduce(collective, local_logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/collective_all_reduce/run.3'"
     ]
    }
   ],
   "source": [
    "experiment.collective_all_reduce(collective, name='mirrortime', description='such desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Experiments/application_1551827646377_0002/collective_all_reduce/run.4'"
     ]
    }
   ],
   "source": [
    "experiment.collective_all_reduce(collective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Distributed Training ParameterServerStrategy (This may fail if not configured ParameterServerStrategy)\n",
    "\n",
    "- `experiment.parameter_server()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps():\n",
    "    assert 'TF_CONFIG' in os.environ\n",
    "    assert devices.get_num_gpus() >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: these ps tests does not complete, it waits indefinitely\n",
    "#experiment.parameter_server(ps, local_logdir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment.parameter_server(ps, local_logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment.parameter_server(ps, name='mirrortime', description='such desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment.parameter_server(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store Tests\n",
    "\n",
    "These tests require that you have the following files in the Resources directory:\n",
    "\n",
    "- `attendances_features.csv`\n",
    "- `games_features.csv`\n",
    "- `players_features.csv`\n",
    "- `season_scores_features.csv`\n",
    "- `teams_features.csv`\n",
    "\n",
    "These files can be downloaded from here: `http://snurran.sics.se/hops/hops-util-py_test/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Resources/attendances_features.csv\n",
      "hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Resources/games_features.csv\n",
      "hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Resources/players_features.csv\n",
      "hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Resources/season_scores_features.csv\n",
      "hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/Resources/teams_features.csv\n",
      "[None, None, None, None, None]"
     ]
    }
   ],
   "source": [
    "list(map(lambda y: print(y), filter(lambda x: \".csv\" in x, hdfs.ls(\"Resources/\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = util._find_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Create Feature Group Operations (`featurestore.create_featuregroup()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fs_sample_data():\n",
    "    resources_path = hdfs.project_path() + \"Resources/\"\n",
    "    games_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"games_features.csv\")\n",
    "    players_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"players_features.csv\")\n",
    "    teams_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"teams_features.csv\")\n",
    "    season_scores_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(resources_path + \"season_scores_features.csv\")\n",
    "    attendances_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"attendances_features.csv\")\n",
    "    return games_features_df,players_features_df,teams_features_df,season_scores_features_df, attendances_features_df\n",
    "games_features_df,players_features_df,teams_features_df,season_scores_features_df, attendances_features_df = load_fs_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : games_features\n",
      "computing feature correlation for: games_features\n",
      "computing feature histograms for: games_features\n",
      "computing cluster analysis for: games_features\n",
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    games_features_df,\n",
    "    \"games_features\",\n",
    "    description=\"Features of average season scores for football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : teams_features\n",
      "computing feature correlation for: teams_features\n",
      "computing feature histograms for: teams_features\n",
      "computing cluster analysis for: teams_features\n",
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_df,\n",
    "    \"teams_features\",\n",
    "    description=\"a spanish version of teams_features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : season_scores_features\n",
      "computing feature correlation for: season_scores_features\n",
      "computing feature histograms for: season_scores_features\n",
      "computing cluster analysis for: season_scores_features\n",
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    season_scores_features_df,\n",
    "    \"season_scores_features\",\n",
    "    description=\"Features of average season scores for football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : attendances_features\n",
      "computing feature correlation for: attendances_features\n",
      "computing feature histograms for: attendances_features\n",
      "computing cluster analysis for: attendances_features\n",
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    attendances_features_df,\n",
    "    \"attendances_features\",\n",
    "    description=\"Features of average attendance of games of football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_1"
     ]
    }
   ],
   "source": [
    "teams_features_1_df = featurestore.get_featuregroup(\"teams_features\")\n",
    "teams_features_2_df = teams_features_1_df.withColumnRenamed(\n",
    "    \"team_id\", \"equipo_id\").withColumnRenamed(\n",
    "    \"team_budget\", \"equipo_presupuesto\").withColumnRenamed(\n",
    "    \"team_position\", \"equipo_posicion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroup_version=1,\n",
    "    job_name=None,\n",
    "    dependencies=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    featuregroup_version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"games_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"season_scores_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"attendances_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_spanish_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_spanish_2\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Utility Operations, \n",
    "\n",
    "- `featurestore.get_metadata()`,\n",
    "- `featurestore.project_featurestore()`, \n",
    "- `featurestore.get_latest_featuregroup_version()`, \n",
    "- `featurestore.get_features_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.get_featurestore_metadata(update_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.project_featurestore() == hdfs.project_name() + \"_featurestore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.project_featurestore() in featurestore.get_project_featurestores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(featurestore.get_project_featurestores()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.get_latest_featuregroup_version(\"teams_features_spanish\") == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.get_latest_featuregroup_version(\"teams_features\") == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"away_team_id\" in featurestore.get_features_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"home_team_id\" in featurestore.get_features_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Read operations of Features and Feature Groups, \n",
    "\n",
    "- `featurestore.get_feature()`, \n",
    "- `featurestore.get_features()`, \n",
    "- `featurestore.get_featuregroup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget FROM teams_features_1"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_feature(\"team_budget\")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 1\n",
    "assert \"team_budget\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget FROM teams_features_1"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_feature(\n",
    "    \"team_budget\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup=\"teams_features\", \n",
    "    featuregroup_version = 1,\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 1\n",
    "assert \"team_budget\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_1"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_featuregroup(\"teams_features\")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_1"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_featuregroup(\n",
    "    \"teams_features\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup_version = 1,\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT attendances_features_1.average_attendance, teams_features_1.team_budget FROM attendances_features_1 JOIN teams_features_1 ON attendances_features_1.`team_id`=teams_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "features = [\"teams_features_1.team_budget\", \"attendances_features_1.average_attendance\"]\n",
    "tmp = featurestore.get_features(features)\n",
    "assert set([\"team_budget\", \"average_attendance\"]) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance FROM attendances_features_1 JOIN teams_features_1 ON attendances_features_1.`team_id`=teams_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroups_version_dict={\n",
    "        \"teams_features\": 1, \n",
    "        \"attendances_features\": 1\n",
    "    }\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroups_version_dict={\n",
    "        \"teams_features\": 1, \n",
    "        \"attendances_features\": 1\n",
    "    },\n",
    "    join_key = \"team_id\",\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT sum_attendance, team_budget, average_attendance, team_position FROM attendances_features_1 JOIN teams_features_1 ON attendances_features_1.`team_id`=teams_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\",\n",
    "    \"team_position\", \"sum_attendance\"\n",
    "    ]\n",
    "tmp = featurestore.get_features(\n",
    "   features\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, team_id FROM teams_features_1"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"team_id\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featuregroups_version_dict = {\n",
    "        \"teams_features\" : 1\n",
    "    }\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, score FROM teams_features_1 JOIN games_features_1 ON games_features_1.home_team_id = teams_features_1.team_id"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\n",
    "    \"SELECT team_budget, score \" \\\n",
    "    \"FROM teams_features_1 JOIN games_features_1 ON \" \\\n",
    "    \"games_features_1.home_team_id = teams_features_1.team_id\")\n",
    "features = ['team_budget', 'score']\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 49\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_1 WHERE team_position < 5"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\"SELECT * FROM teams_features_1 WHERE team_position < 5\")\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns\n",
    "for x in tmp.toPandas()[\"team_position\"].values:\n",
    "    assert x < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_1 WHERE team_position < 5"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\"SELECT * FROM teams_features_1 WHERE team_position < 5\",\n",
    "                featurestore=featurestore.project_featurestore(), \n",
    "                 dataframe_type = \"spark\")\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns\n",
    "for x in tmp.toPandas()[\"team_position\"].values:\n",
    "    assert x < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Test Insert Operations in Existing Feature Groups, `featurestore.insert_into_featuregroup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "schema = StructType([StructField(\"equipo_id\", IntegerType(), True),\n",
    "                     StructField(\"equipo_presupuesto\", FloatType(), True),\n",
    "                     StructField(\"equipo_posicion\", IntegerType(), True)\n",
    "                        ])\n",
    "sample_df = sqlContext.createDataFrame([(999, 41251.52, 1), (998, 1319.4, 8), (997, 21219.1, 2)], schema)\n",
    "insert_count = sample_df.count()\n",
    "assert insert_count == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_spanish_1"
     ]
    }
   ],
   "source": [
    "spanish_team_features_df = featurestore.get_featuregroup(\n",
    "    \"teams_features_spanish\")\n",
    "pre_insert_count = spanish_team_features_df.count()\n",
    "assert pre_insert_count == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_spanish_1"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\", \n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "spanish_team_features_df_updated = featurestore.get_featuregroup(\n",
    "    \"teams_features_spanish\")\n",
    "\n",
    "after_insert_count = spanish_team_features_df_updated.count()\n",
    "assert after_insert_count == 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_spanish_1"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup_version=1, \n",
    "    mode=\"append\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False, \n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False, \n",
    "    stat_columns=None, \n",
    "    num_bins=20, \n",
    "    corr_method='pearson',\n",
    "    num_clusters=5\n",
    ")\n",
    "\n",
    "after_insert_count2 = featurestore.get_featuregroup(\"teams_features_spanish\").count()\n",
    "assert after_insert_count2 == 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_spanish_1"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "\n",
    "count_after_overwrite = featurestore.get_featuregroup(\"teams_features_spanish\").count()\n",
    "assert count_after_overwrite == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test integration of feature store with Numpy, Pandas and plain Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "pandas_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], dataframe_type=\"pandas\")\n",
    "assert \"team_budget\" in pandas_df.columns.values\n",
    "assert \"average_attendance\" in pandas_df.columns.values\n",
    "assert len(pandas_df) == 50\n",
    "assert len(pandas_df.columns.values) == 2\n",
    "assert isinstance(pandas_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "numpy_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"numpy\")\n",
    "assert numpy_df.shape[0] == 50\n",
    "assert numpy_df.shape[1] == 2\n",
    "assert isinstance(numpy_df, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "python_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"python\")\n",
    "assert len(python_df) == 50\n",
    "assert isinstance(python_df, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "spark_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"spark\")\n",
    "assert spark_df.count() == 50\n",
    "assert isinstance(spark_df, DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "# Let's rename the columns to differentiate this feature group from existing ones in the feature store\n",
    "pandas_df.columns = [\"team_budget_test\", \"average_attendance_test\"]\n",
    "\n",
    "featurestore.create_featuregroup(\n",
    "    pandas_df,\n",
    "    \"pandas_test_example\",\n",
    "    description=\"test featuregroup created from pandas dataframe\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "assert \"pandas_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM pandas_test_example_1\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM pandas_test_example_1"
     ]
    }
   ],
   "source": [
    "count_pre_pandas_insert_overwrite = featurestore.get_featuregroup(\"pandas_test_example\").count()\n",
    "featurestore.insert_into_featuregroup(\n",
    "    pandas_df, \n",
    "    \"pandas_test_example\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "count_after_pandas_insert_overwrite = featurestore.get_featuregroup(\"pandas_test_example\").count()\n",
    "assert count_pre_pandas_insert_overwrite == count_after_pandas_insert_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    numpy_df,\n",
    "    \"numpy_test_example\",\n",
    "    description=\"test featuregroup created from numpy matrix\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "assert \"numpy_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM numpy_test_example_1\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM numpy_test_example_1"
     ]
    }
   ],
   "source": [
    "numpy_test_df_count_pre_insert_overwrite = featurestore.get_featuregroup(\"numpy_test_example\", dataframe_type=\"spark\").count()\n",
    "featurestore.insert_into_featuregroup(\n",
    "    numpy_df, \n",
    "    \"numpy_test_example\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "numpy_test_df_count_after_insert_overwrite = featurestore.get_featuregroup(\"numpy_test_example\", dataframe_type=\"spark\").count()\n",
    "assert numpy_test_df_count_pre_insert_overwrite == numpy_test_df_count_pre_insert_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM python_test_example_1"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    python_df,\n",
    "    \"python_test_example\",\n",
    "    description=\"test featuregroup created from python 2D list\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "\n",
    "python_test_df_count_pre_insert_overwrite = featurestore.get_featuregroup(\"python_test_example\", dataframe_type=\"spark\").count()\n",
    "assert \"python_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM python_test_example_1"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    python_df, \n",
    "    \"python_test_example\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "\n",
    "python_test_df_count_after_insert_overwrite = featurestore.get_featuregroup(\"python_test_example\", dataframe_type=\"spark\").count()\n",
    "assert python_test_df_count_pre_insert_overwrite == python_test_df_count_after_insert_overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test update Feature Store Statistics `featurestore.update_featuregroup_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_1\n",
      "computing descriptive statistics for : teams_features\n",
      "computing feature correlation for: teams_features\n",
      "computing feature histograms for: teams_features\n",
      "computing cluster analysis for: teams_features"
     ]
    }
   ],
   "source": [
    "featurestore.update_featuregroup_stats(\"teams_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT * FROM teams_features_1\n",
      "computing descriptive statistics for : teams_features\n",
      "computing feature correlation for: teams_features\n",
      "computing feature histograms for: teams_features\n",
      "computing cluster analysis for: teams_features"
     ]
    }
   ],
   "source": [
    "featurestore.update_featuregroup_stats(\n",
    "    \"teams_features\", \n",
    "    featuregroup_version=1, \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    descriptive_statistics=True,\n",
    "    feature_correlation=True, \n",
    "    feature_histograms=True,\n",
    "    cluster_analysis=True,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Write Training Dataset Operations \n",
    "\n",
    "- `featurestore.get_latest_training_dataset_version()`\n",
    "- `create_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use demo_featurestore_admin000_featurestore\n",
      "Running sql: SELECT team_budget, average_attendance, team_position FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id`"
     ]
    }
   ],
   "source": [
    "features_df = featurestore.get_features(\n",
    "    [\"team_budget\", \"average_attendance\",\n",
    "    \"team_position\"]\n",
    ")\n",
    "latest_version = featurestore.get_latest_training_dataset_version(\"team_position_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    training_dataset_version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_csv\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"csv\",\n",
    "    training_dataset_version= 1,\n",
    "    job_name=None,\n",
    "    dependencies=[],\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_tsv\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"tsv\",\n",
    "    training_dataset_version=1,\n",
    "    job_name=None,\n",
    "    dependencies=[],\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_parquet\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"parquet\",\n",
    "    training_dataset_version=1,\n",
    "    job_name=None,\n",
    "    dependencies=[],\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_orc\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"orc\",\n",
    "    training_dataset_version=1,\n",
    "    job_name=None,\n",
    "    dependencies=[],\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_avro\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"avro\",\n",
    "    training_dataset_version=1,\n",
    "    job_name=None,\n",
    "    dependencies=[],\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_hdf5\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"hdf5\",\n",
    "    training_dataset_version=1,\n",
    "    job_name=None,\n",
    "    dependencies=[],\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_npy\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"npy\",\n",
    "    training_dataset_version=1,\n",
    "    job_name=None,\n",
    "    dependencies=[],\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info[0] >= 3:\n",
    "    PetastormSchema = Unischema('team_position_prediction_petastorm_schema', [\n",
    "        UnischemaField('team_budget', np.float32, (), ScalarCodec(FloatType()), False),\n",
    "        UnischemaField('average_attendance', np.float32, (), ScalarCodec(FloatType()), False),\n",
    "        UnischemaField('team_position', np.int32, (), ScalarCodec(IntegerType()), False)\n",
    "    ])\n",
    "\n",
    "    petastorm_args = {\n",
    "        \"schema\": PetastormSchema\n",
    "    }\n",
    "\n",
    "    featurestore.create_training_dataset(\n",
    "        features_df, \"team_position_prediction_petastorm\",\n",
    "        description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "        featurestore=featurestore.project_featurestore(),\n",
    "        data_format=\"petastorm\",\n",
    "        training_dataset_version=1,\n",
    "        job_name=None,\n",
    "        dependencies=[],\n",
    "        descriptive_statistics=False,\n",
    "        feature_correlation=False,\n",
    "        feature_histograms=False,\n",
    "        cluster_analysis=False,\n",
    "        stat_columns=None,\n",
    "        petastorm_args=petastorm_args\n",
    "    )\n",
    "else:\n",
    "    print(\"Petastorm is only supported in python 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = ['team_position_prediction_1', 'team_position_prediction_csv_1', \n",
    "       'team_position_prediction_tsv_1', 'team_position_prediction_parquet_1', \n",
    "       'team_position_prediction_orc_1', 'team_position_prediction_avro_1', \n",
    "       'team_position_prediction_hdf5_1', 'team_position_prediction_npy_1', \n",
    "       'team_position_prediction_petastorm_1', 'team_position_prediction_npy_2']\n",
    "assert set(fgs) == set(featurestore.get_training_datasets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Insert into an existing training dataset, `featurestore.insert_into_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pre_insert = featurestore.get_training_dataset(\"team_position_prediction_csv\").count()\n",
    "featurestore.insert_into_training_dataset(\n",
    "    features_df, \n",
    "    \"team_position_prediction_csv\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    training_dataset_version=featurestore.get_latest_training_dataset_version(\"team_position_prediction_csv\")\n",
    ")\n",
    "count_after_insert = featurestore.get_training_dataset(\"team_position_prediction_csv\").count()\n",
    "assert count_pre_insert == count_after_insert # td only support overwrites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Training Dataset Utility Methods\n",
    "\n",
    "- `featurestore.get_training_dataset_path()`\n",
    "- `featurestore.get_training_dataset_tf_record_schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.project_path() in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.project_name() + \"_Training_Datasets\" in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"team_position_prediction_csv\" in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_schema = featurestore.get_training_dataset_tf_record_schema(\"team_position_prediction\")\n",
    "assert tf_schema == {'team_budget': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'average_attendance': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'team_position': tf.FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = featurestore.get_training_dataset(\"team_position_prediction\")\n",
    "tf_schema = featurestore.get_dataframe_tf_record_schema(features_df)\n",
    "assert tf_schema == {'team_budget': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'average_attendance': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'team_position': tf.FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test update Training Dataset stats\n",
    "\n",
    "- `featurestore.update_training_dataset_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : team_position_prediction\n",
      "computing feature correlation for: team_position_prediction\n",
      "computing feature histograms for: team_position_prediction\n",
      "computing cluster analysis for: team_position_prediction"
     ]
    }
   ],
   "source": [
    "featurestore.update_training_dataset_stats(\"team_position_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : team_position_prediction\n",
      "computing feature correlation for: team_position_prediction\n",
      "computing feature histograms for: team_position_prediction\n",
      "computing cluster analysis for: team_position_prediction"
     ]
    }
   ],
   "source": [
    "featurestore.update_training_dataset_stats(\n",
    "    \"team_position_prediction\", \n",
    "    training_dataset_version=1, \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    descriptive_statistics=True,\n",
    "    feature_correlation=True, \n",
    "    feature_histograms=True,\n",
    "    cluster_analysis=True,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Read Training Datasets API `featurestore.get_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['team_budget', 'average_attendance', 'team_position']\n",
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_csv\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_hdf5\")\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_petastorm\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_avro\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_orc\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_tsv\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_npy\")\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_parquet\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test default config \n",
    "\n",
    "- `kafka.get_default_config()`, \n",
    "- `kafka.get_security_protocol()`,\n",
    "- `kafka.get_broker_endpoints_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = kafka.get_kafka_default_config()\n",
    "assert \"bootstrap.servers\" in config\n",
    "assert \"security.protocol\" in config\n",
    "assert \"ssl.ca.location\" in config\n",
    "assert \"ssl.key.location\" in config\n",
    "assert \"ssl.certificate.location\" in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(kafka.get_security_protocol()) > 0\n",
    "assert len(kafka.get_broker_endpoints_list()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLS Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test access to TLS tokens\n",
    "\n",
    "- `tls.get_key_store()`\n",
    "- `tls.get_trust_store()`\n",
    "- `tls.get_key_store_pwd()`\n",
    "- `tls.get_trust_store_pwd()`\n",
    "- `tls.get_client_certificate_location()`\n",
    "- `tls.get_client_key_location()`\n",
    "- `tls.get_ca_chain_location()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tls.get_key_store()) > 0\n",
    "assert len(tls.get_trust_store()) > 0\n",
    "assert len(tls.get_key_store_pwd()) > 0\n",
    "assert len(tls.get_trust_store_pwd()) > 0\n",
    "assert len(tls.get_client_certificate_location()) > 0\n",
    "assert len(tls.get_client_key_location()) > 0\n",
    "assert len(tls.get_ca_chain_location()) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}